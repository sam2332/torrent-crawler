{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83f733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scraper():\n",
    "    results = []\n",
    "    \n",
    "    def getResults(self):\n",
    "        return self.results\n",
    "    \n",
    "    def Run(self, search):\n",
    "        raise Exception(\"Base Class Run Called\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8578a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from faker import Faker\n",
    "fake = Faker()\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d7f23b-80c6-4028-9fbb-45638690fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraper(Scraper):\n",
    "    session = None\n",
    "    \n",
    "    def getClient(self):\n",
    "        if self.session is None:\n",
    "            self.session = requests.Session()\n",
    "            self.session.headers['user-agent'] = fake.chrome()\n",
    "        return self.session\n",
    "    \n",
    "    def getSearchUrl(self, search, page):\n",
    "        return f\"https://testing.to/search/{search}/{page}/\"\n",
    "    \n",
    "    def Run(self, search):\n",
    "        client = self.getClient()\n",
    "        url = self.getSearchUrl(search)\n",
    "        res = client.get(url)\n",
    "        soup =BeautifulSoup(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ade77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraper1337x(WebScraper):\n",
    "    \n",
    "    def getSearchUrl(self, search, page):\n",
    "        return f\"https://1337x.to/sort-search/{search}/seeders/desc/{page}/\"\n",
    "    \n",
    "    def Run(self, search,pages = 3):\n",
    "        client = self.getClient()\n",
    "        titles = ['name', 'seed', 'leech', 'time', 'size', 'uploader']\n",
    "        for page_number in range(1,pages+1):\n",
    "            url = self.getSearchUrl(search,page_number)\n",
    "            res = client.get(url)\n",
    "            soup =BeautifulSoup(res.text)\n",
    "            table = soup.find_all('table')[0]\n",
    "            for row in table.find_all('tr'):\n",
    "                tds = [i.text.strip() for i in row.find_all('td')]\n",
    "                out = dict(zip(titles,tds))\n",
    "                if len(out.keys())>0:\n",
    "                    yield out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138fea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in WebScraper1337x().Run(\"Sing 2\"):\n",
    "    print(result['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b96ff0-3c26-45dd-a5fc-4484cfce8741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57268295-2e77-4886-8847-f40b1ea3f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScraperkickassTorrents_to(WebScraper):\n",
    "    \n",
    "    def getSearchUrl(self, search, page):\n",
    "        return f\"https://kickasstorrents.to/usearch/{search}/{page}/?sortby=seeders&sort=desc\"\n",
    "    \n",
    "    def Run(self, search,pages = 1):\n",
    "        client = self.getClient()\n",
    "        titles = ['name', 'size', 'uploader', 'time', 'seed', 'leech']\n",
    "        for page_number in range(1,pages+1):\n",
    "            url = self.getSearchUrl(search,page_number)\n",
    "            res = client.get(url)\n",
    "            soup =BeautifulSoup(res.text)\n",
    "            table = soup.find_all('table')[0]\n",
    "            table = table.find_all('table')[0]\n",
    "            table = table.find_all('table')[0]\n",
    "            for row in table.find_all('tr'):\n",
    "                tds = [i.text.strip() for i in row.find_all('td')]\n",
    "                out = dict(zip(titles,tds))\n",
    "                if len(out.keys())>0:\n",
    "                    out['name'] = out['name'].split('\\n')[0]\n",
    "                    yield out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a2657",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in WebScraperkickassTorrents_to().Run(\"Sing 2\"):\n",
    "    print(result['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578774a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class WebScraperRarbg(WebScraper):\n",
    "    \n",
    "    def getSearchUrl(self, search, page):\n",
    "        return f\"https://rarbg.to/torrents.php?search={search}&order=seeders&by=DESC&page={page}\"\n",
    "    \n",
    "    def Run(self, search,pages = 1):\n",
    "        client = self.getClient()\n",
    "        titles = ['cat', 'name', 'time', 'size', 'seed', 'leech','comments','uploader']\n",
    "        for page_number in range(1,pages+1):\n",
    "            url = self.getSearchUrl(search,page_number)\n",
    "            res = client.get(url)\n",
    "            soup =BeautifulSoup(res.text)\n",
    "            table = soup.find('table',{'class':'lista2t'})\n",
    "            for row in table.find_all('tr'):\n",
    "                tds = [i.text.strip() for i in row.find_all('td')]\n",
    "                out = dict(zip(titles,tds))\n",
    "                if len(out.keys())>0:\n",
    "                    if out['cat'] =='Cat.':\n",
    "                        continue\n",
    "                    del out['cat']\n",
    "                    yield out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47871bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in WebScraperRarbg().Run(\"Sing 2\"):\n",
    "    print(result['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af392834",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
